{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 6,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 6,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 从一个小型数据集上从头开始训练一个CNN\n",
    "\n",
    "### 数据集中包含4K张猫狗图片，2K用于训练，1K用于验证，1K用于测试\n",
    "\n",
    "## 1、将图片复制到训练、验证和测试的目录上"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 8,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] 当文件已存在时，无法创建该文件。: 'E:\\\\cats_dogs_small'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d1558755eb0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#保存较小数据集的目录\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'E:\\cats_dogs_small'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#创建一个名为cats_dogs_small的文件夹.默认的 mode 是 0777 (八进制)。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#分别对应划分后的训练、验证和测试的目录 即在创建好的文件夹里面再创建训练、验证、测试子文件夹\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] 当文件已存在时，无法创建该文件。: 'E:\\\\cats_dogs_small'"
     ]
    }
   ],
   "source": [
    "import os,shutil\n",
    "#原始数据解压目录的路径\n",
<<<<<<< HEAD
    "original_datasets_dir = r'E:\\dogs-cats-data\\train\\train'   #阻止反斜杠转义\n",
=======
    "original_datasets_dir = r'E:\\cat vs dog\\train\\train'   #阻止反斜杠转义\n",
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
    "#保存较小数据集的目录\n",
    "base_dir = r'E:\\cats_dogs_small'\n",
    "os.mkdir(base_dir)   #创建一个名为cats_dogs_small的文件夹.默认的 mode 是 0777 (八进制)。\n",
    "\n",
    "#分别对应划分后的训练、验证和测试的目录 即在创建好的文件夹里面再创建训练、验证、测试子文件夹\n",
    "train_dir = os.path.join(base_dir,'train') #将目录和文件名合并成一个路径\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "#猫狗的训练目录 即在训练目录中创建猫、狗类的子文件夹\n",
    "train_cats_dir = os.path.join(train_dir,'cats') \n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "#猫狗的验证目录\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "#猫狗的测试目录\n",
    "test_cats_dir = os.path.join(test_dir,'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir,'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "#将前1000张猫图像复制到Train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(train_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    scr =os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(validation_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(test_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)   #copyfile(1,2)把1复制到2中\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(train_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(validation_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    scr= os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(test_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 9,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cats: 1000\n",
      "validation dogs: 500\n",
      "test cats: 500\n"
     ]
    }
   ],
   "source": [
    "print('training cats:',len(os.listdir(train_cats_dir)))\n",
    "\n",
    "print('validation dogs:',len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "print('test cats:',len(os.listdir(test_cats_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、构建网络\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 10,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
<<<<<<< HEAD
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
=======
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))  #图片大小150*150，3表示彩色图像\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、配置模型\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 34,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
<<<<<<< HEAD
    "              metrics=['acc'])"
=======
    "              metrics=['acc'])\n",
    "\n",
    "#model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=0.9, nesterov=True), \n",
    " #             loss='binary_crossentropy',\n",
    "  #            metrics=['acc'])"
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、数据预处理——使用ImageDataGenerator从目录中读取图像\n",
    "将数据输入到神经网络之前，应将数据格式化为经过预处理的浮点数张量\n",
    "当前图片以JPEG文件存储硬盘中，数据预处理步骤：\n",
    "* （1）读取图像文件\n",
    "* （2）将JPEG文件解码为RGB像素网格\n",
    "* （3）将这些像素网格装换为浮点数张量\n",
    "* （4）将像素值（0-255范围内缩放到[0-1]区间）——神经网络喜欢处理较小的输入值\n",
    "\n",
    "keras有一个图像处理辅助工具的模块，位于keras.preprocessing.image，它包含了ImageDataGenerator类，可以快速创建Python生成器（一个类似于迭代器的对象，可以喝for... in 运算符一起使用的对象，生成器是用yield运算符来构造的），能将硬盘上的图像文件自动转换为与处理好的张量批量"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 30,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#将所有图像除以255缩放到[0-1]\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)    #datagen数据发生器\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(      #数据集生成器\n",
    "    train_dir,    #目标目录\n",
    "    target_size=(150,150),   #将所有图像的大小调整为150*150\n",
    "    batch_size=20,   #批处理数据的大小\n",
    "    class_mode='binary')   #因为使用了binary_crossetropy损失，所以需要二进制标签 \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看其中一个训练其生成，一个RGB图像[形状为(20,150,150,3)]与二进制标签[(20,)]组成的批量。每个样本保存20个样本"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 31,
   "metadata": {},
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
=======
    "for data_batch,labels_batch in train_generator:\n",
    "    print('data batch shape:',data_batch.shape)\n",
    "    print('labels batch shape:',labels_batch.shape)\n",
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
    "    break    #阻止生成器不停地生成这些批量，阻止循环目标文件夹中的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5、利用批量生成器拟合模型\n",
    "\n",
    "#### 利用生成器进行拟合，故用fit_generator方法，"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 35,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/20\n",
      "100/100 [==============================] - 53s 525ms/step - loss: 0.5767 - acc: 0.6980 - val_loss: 0.5203 - val_acc: 0.6720\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 52s 522ms/step - loss: 0.5439 - acc: 0.7275 - val_loss: 0.5248 - val_acc: 0.6910\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5177 - acc: 0.7425 - val_loss: 0.5443 - val_acc: 0.6580\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4986 - acc: 0.7470 - val_loss: 0.6038 - val_acc: 0.6820\n",
      "Epoch 5/20\n",
      " 97/100 [============================>.] - ETA: 1s - loss: 0.4634 - acc: 0.7784"
=======
      "Epoch 1/30\n",
      "  2/100 [..............................] - ETA: 2:52 - loss: 0.6799 - acc: 0.6500"
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
<<<<<<< HEAD
      "\u001b[1;32m<ipython-input-19-8b2244b0e217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     validation_steps=50)   #从验证生成器中抽取50个批次用于评估\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
=======
      "\u001b[1;32m<ipython-input-35-5dd5aad837a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     validation_steps=50)\n\u001b[0m",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,  #生成器，可不停生成输入和目标组成的批量                            \n",
<<<<<<< HEAD
    "    steps_per_epoch=100,  #由于不停生成，故需知道每轮从生成器中抽取100个样本(运行100次梯度下降)                            \n",
    "    epochs=20,                             \n",
    "    validation_data=validation_generator,                            \n",
    "    validation_steps=50)   #从验证生成器中抽取50个批次用于评估"
=======
    "    steps_per_epoch=100,  #由于不停生成，故需知道每轮从生成器中抽取多少样本(运行多少次梯度下降)                            \n",
    "    epochs=30,                             \n",
    "    validation_data=validation_generator,                            \n",
    "    validation_steps=50)"
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制损失曲线和精度曲线"
<<<<<<< HEAD
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc) +1)  #\n",
    "\n",
    "plt.plot(epochs,acc,'bo',label='Traning acc')\n",
    "plt.plot(epochs,val_acc,'b',label = 'Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure() #创建新的图形\n",
    "\n",
    "plt.plot(epochs,loss,'bo',label = 'Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and Validation lossfunction')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从图中得出验证集的精度在0.7左右。且产生很明显的过拟合，所以使用数据增强和dropout来降低过拟合\n",
    "     解决过拟合：1、更多的数据\n",
    "             2、减小网络容量\n",
    "             3、regulaization正则化\n",
    "             4、添加 dropout\n",
    "### 使用数据增强——利用ImageDataGenerator来设置数据增强\n",
    "#### 因为样本过少，无法泛化到新数据的模型，利用IDG来生成可信图像的随机变换来增加样本，使模型在训练时不会两次查看完全相同的图像，可让模型观察到数据更多内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-a1b431db175b>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-a1b431db175b>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    fnames = [os.path.join(train_cats_dir,fname) for fname in os,listdir(train_cats_dir)]\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#数据增强\n",
    "\n",
    "datagen=TmageDataGenerator(rotation_range=40,  #角度值，(0-180)图像随机旋转的的角度范围\n",
    "                           width_shift_range=0.2,  #图像在水平或垂直方向上平移的范围\n",
    "                           heigth_shift_range=0.2,\n",
    "                           shear_range=0.2,  #随机错切变换的角度\n",
    "                           zoom_range=0.2,   #随机缩放的范围\n",
    "                           horizontal_flip=True,  #随即将一半图像水平翻转\n",
    "                           fill_mode='nearest')  #用于填充新创建像素的方法，新像素可能来自旋转等\n",
    "  \n",
    "#显示几个随机增强后的训练图像\n",
    "from keras.preprocessing import image   #导入图像预处理工具模块\n",
    "\n",
    "fnames = [os.path.join(train_cats_dir,fname) for fname in os,listdir(train_cats_dir)]\n",
    "\n",
    "img_path = fname[3]  #选一张图像进行增强\n",
    "\n",
    "img = image.load_img(img_path,target_size=(150,150)) #读取图像并调整大小\n",
    "\n",
    "x = image.img_to_array(img) #将其转换为形状（150,150,3）的numpy数组\n",
    "\n",
    "x = x.reshape((1,) + x.shape)  #将其形状改变为（1,150,150,3）\n",
    "\n",
    "#生成随机变换后的图像批量，循环是无限需break\n",
    "i=0\n",
    "for batch in datagen.flow(x,batch_size=1):       \n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image,array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 ==0:\n",
    "        break\n",
    "        \n",
    "plt.show()"
=======
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history_history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = rang(1,len(acc) +1)  #\n",
    "\n",
    "plt.plot(epochs,acc,'bo',label='Traning acc')\n",
    "plt.plot(epochs,val_acc,'b',label = 'Validation acc')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure() #创建新的图形\n",
    "\n",
    "plt.plot(epochs,loss,'bo',label = 'Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and Validation lossfunction')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从图中得出验证集的精度在0.7左右。且产生很明显的过拟合，所以使用数据增强和dropout来降低过拟合\n",
    "### 使用数据增强——利用ImageDataGenerator来设置数据增强\n",
    "#### 因为样本过少，无法泛化到新数据的模型，利用IDG来生成可信图像的随机变换来增加样本，使模型在训练时不会两次查看完全相同的图像，可让模型观察到数据更多内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-38bb2b3f8799>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-38bb2b3f8799>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    fnames = [os.path.join(train_cats_dir,fname) for fname in os,listdir(train_cats_dir)]\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#数据增强\n",
    "\n",
    "datagen=TmageDataGenerator(rotation_range=40,  #角度值，(0-180)图像随机旋转的的角度范围\n",
    "                           width_shift_range=0.2,  #图像在水平或垂直方向上平移的范围\n",
    "                           heigth_shift_range=0.2,\n",
    "                           shear_range=0.2,  #随机错切变换的角度\n",
    "                           zoom_range=0.2,   #随机缩放的范围\n",
    "                           horizontal_flip=True,  #随即将一半图像水平翻转\n",
    "                           fill_mode='nearest')  #用于填充新创建像素的方法，新像素可能来自旋转等\n",
    "  \n",
    "#显示几个随机增强后的训练图像\n",
    "from keras.preprocessing import image   #导入图像预处理工具模块\n",
    "\n",
    "fnames = [os.path.join(train_cats_dir,fname) for fname in os,listdir(train_cats_dir)]\n",
    "\n",
    "img_path = fname[3]  #选一张图像进行增强\n",
    "\n",
    "img = image.load_img(img_path,target_size=(150,150)) #读取图像并调整大小\n",
    "\n",
    "x = image.img_to_array(img) #将其转换为形状（150,150,3）的numpy数组\n",
    "\n",
    "x = x.reshape((1,) + x.shape)  #将其形状改变为（1,150,150,3）\n",
    "\n",
    "#生成随机变换后的图像批量，循环是无限需break\n",
    "i=0\n",
    "for batch in datagen.flow(x,batch_size=1):       \n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image,array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 ==0:\n",
    "        break\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> c337206591097467bb8e43ddc6effa075ae488fb
    "定义一个包含dropout的CNN\n",
    "add(layers.Dropout(0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
