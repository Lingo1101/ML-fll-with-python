{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从一个小型数据集上从头开始训练一个CNN\n",
    "\n",
    "### 数据集中包含4K张猫狗图片，2K用于训练，1K用于验证，1K用于测试\n",
    "\n",
    "## 1、将图片复制到训练、验证和测试的目录上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "#原始数据解压目录的路径\n",
    "original_datasets_dir = r'E:\\cat vs dog\\train\\train'\n",
    "#保存较小数据集的目录\n",
    "base_dir = r'E:\\cats_dogs_small'\n",
    "os.mkdir(base_dir)   #创建一个名为cats_dogs_small的文件夹.默认的 mode 是 0777 (八进制)。\n",
    "\n",
    "#分别对应划分后的训练、验证和测试的目录 即在创建好的文件夹里面再创建训练、验证、测试子文件夹\n",
    "train_dir = os.path.join(base_dir,'train') #将目录和文件名合并成一个路径\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "#猫狗的训练目录 即在训练目录中创建猫、狗类的子文件夹\n",
    "train_cats_dir = os.path.join(train_dir,'cats') \n",
    "os.mkdir(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "#猫狗的验证目录\n",
    "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir,'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "#猫狗的测试目录\n",
    "test_cats_dir = os.path.join(test_dir,'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir,'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "#将前1000张猫图像复制到Train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(train_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    scr =os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(validation_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(test_cats_dir,fname)\n",
    "    shutil.copyfile(scr,dst)   #copyfile(1,2)把1复制到2中\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(train_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    scr = os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(validation_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n",
    "\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    scr= os.path.join(original_datasets_dir,fname)\n",
    "    dst = os.path.join(test_dogs_dir,fname)\n",
    "    shutil.copyfile(scr,dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cats: 1000\n"
     ]
    }
   ],
   "source": [
    "print('training cats:',len(os.listdir(train_cats_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、构建网络\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))  #图片大小150*150，3表示彩色图像\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、配置模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=le-4),\n",
    "              matrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、数据预处理\n",
    "将数据输入到神经网络之前，应将数据格式化为经过预处理的浮点数张量\n",
    "当前图片以JPEG文件存储硬盘中，数据预处理步骤：\n",
    "（1）读取图像文件\n",
    "（2）将JPEG文件解码为RGB像素网格\n",
    "（3）将这些像素网格装换为浮点数张量\n",
    "（4）将像素值（0~255范围内缩放到[0~1]区间）——神经网络喜欢处理较小的输入值\n",
    "\n",
    "keras有一个图像处理辅助工具的模块，位于keras.preprocessing.image，它包含了ImageDataGenerator类，可以快速创建Python生成器，能将硬盘上的图像文件自动转换为与处理好的张量批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
